{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56583d18-e1a2-47c8-8297-a185c761741e",
   "metadata": {},
   "source": [
    "# As a simple experiment, try to see if we can classify spots with colonic epithelial cells using spatial transcriptomics data\n",
    "\n",
    "Use EPCAM expression on C.diff.C1 and predict on C.diff.B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d02441-13be-49cd-b2cd-226c522579f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from steml.recipes import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2150fb-2d60-4761-bf44-5ad4d2ee4c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [\n",
    "    ('C.diff', 'A1', 5),\n",
    "    ('C.diff', 'B1', 20),\n",
    "    ('C.diff', 'C1', 20),\n",
    "    ('H.pylori', 'A1', 5),\n",
    "    ('H.pylori', 'B1', 3),\n",
    "    ('H.pylori', 'C1', 1),\n",
    "    ('H.pylori', 'D1', 0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31943a4f-52f9-40b3-8f7c-52b7fdf450f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-15 09:33:16 - INFO - _log:27 - Logging configuration was loaded. Log messages can be found at /mnt/data5/output/tiles/gi-infection-scaled/C.diff/A1/label.log.\n",
      "2022-07-15 09:33:24 - INFO - _preprocess:168 - labeled 608/710 (0.856) as epithelium at /mnt/data5/output/tiles/gi-infection-scaled/C.diff/A1\n",
      "2022-07-15 09:33:24 - INFO - _preprocess:169 - (EPCAM>5)\n",
      "2022-07-15 09:33:24 - INFO - _log:27 - Logging configuration was loaded. Log messages can be found at /mnt/data5/output/tiles/gi-infection-scaled/C.diff/B1/label.log.\n",
      "2022-07-15 09:33:31 - INFO - _preprocess:168 - labeled 258/555 (0.465) as epithelium at /mnt/data5/output/tiles/gi-infection-scaled/C.diff/B1\n",
      "2022-07-15 09:33:31 - INFO - _preprocess:169 - (EPCAM>20)\n",
      "2022-07-15 09:33:31 - INFO - _log:27 - Logging configuration was loaded. Log messages can be found at /mnt/data5/output/tiles/gi-infection-scaled/C.diff/C1/label.log.\n",
      "2022-07-15 09:33:51 - INFO - _preprocess:168 - labeled 445/2891 (0.154) as epithelium at /mnt/data5/output/tiles/gi-infection-scaled/C.diff/C1\n",
      "2022-07-15 09:33:51 - INFO - _preprocess:169 - (EPCAM>20)\n",
      "2022-07-15 09:33:51 - INFO - _log:27 - Logging configuration was loaded. Log messages can be found at /mnt/data5/output/tiles/gi-infection-scaled/H.pylori/A1/label.log.\n",
      "2022-07-15 09:33:58 - INFO - _preprocess:168 - labeled 371/551 (0.673) as epithelium at /mnt/data5/output/tiles/gi-infection-scaled/H.pylori/A1\n",
      "2022-07-15 09:33:58 - INFO - _preprocess:169 - (EPCAM>5)\n",
      "2022-07-15 09:33:59 - INFO - _log:27 - Logging configuration was loaded. Log messages can be found at /mnt/data5/output/tiles/gi-infection-scaled/H.pylori/B1/label.log.\n",
      "2022-07-15 09:34:06 - INFO - _preprocess:168 - labeled 489/791 (0.618) as epithelium at /mnt/data5/output/tiles/gi-infection-scaled/H.pylori/B1\n",
      "2022-07-15 09:34:06 - INFO - _preprocess:169 - (EPCAM>3)\n",
      "2022-07-15 09:34:06 - INFO - _log:27 - Logging configuration was loaded. Log messages can be found at /mnt/data5/output/tiles/gi-infection-scaled/H.pylori/C1/label.log.\n",
      "2022-07-15 09:34:14 - INFO - _preprocess:168 - labeled 617/757 (0.815) as epithelium at /mnt/data5/output/tiles/gi-infection-scaled/H.pylori/C1\n",
      "2022-07-15 09:34:14 - INFO - _preprocess:169 - (EPCAM>1)\n",
      "2022-07-15 09:34:14 - INFO - _log:27 - Logging configuration was loaded. Log messages can be found at /mnt/data5/output/tiles/gi-infection-scaled/H.pylori/D1/label.log.\n",
      "2022-07-15 09:34:20 - INFO - _preprocess:168 - labeled 471/804 (0.586) as epithelium at /mnt/data5/output/tiles/gi-infection-scaled/H.pylori/D1\n",
      "2022-07-15 09:34:20 - INFO - _preprocess:169 - (EPCAM>0)\n"
     ]
    }
   ],
   "source": [
    "for slide, section, threshold in thresholds:\n",
    "    label(\n",
    "        feature_barcode_matrix=f'/mnt/data5/output/count/gi-infection/{slide}/{section}/outs/filtered_feature_bc_matrix',\n",
    "        conditions=[[('EPCAM', False, threshold)]],\n",
    "        name='epithelium',\n",
    "        output_dir=f'/mnt/data5/output/tiles/gi-infection-scaled/{slide}/{section}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a85c2d3-3b75-4567-98a6-f3ecadacfe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from steml.recipes import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8cd16a4-a77d-4ca9-b301-02887013c0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train in module steml.recipes._train:\n",
      "\n",
      "train(label: str, num_classes: int, train_csv: str, activation: str, batch_size: int, epochs: int, lr: float, loss: str, metrics: List[str], output_dir: str, num_workers: int, callback_monitor: str, cache: bool = False, shuffle_train: bool = True, augment_train: bool = True, balance_train: bool = False, val_csv: Union[str, NoneType] = None, shuffle_val: bool = True, augment_val: bool = True, balance_val: bool = False, test_csv: Union[str, NoneType] = None, patience: Union[int, NoneType] = None, lr_reduction: Union[float, NoneType] = None, lr_patience: Union[int, NoneType] = None, num_reductions: Union[int, NoneType] = None, min_delta: float = 0.0001, gpu_config: Union[Tuple[int, int], NoneType] = None, log_level: steml.defines.LogLevel = <LogLevel.INFO: 20>, skip_log_config: bool = False) -> None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e50c8157-200e-45ac-9e33-5159870a6211",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 11:44:35 - INFO - _log:27 - Logging configuration was loaded. Log messages can be found at /mnt/data5/output/train/colon-epithelium/train.log.\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 112, 112, 64) 9472        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 56, 56, 64)   36928       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 56, 56, 64)   256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 56, 56, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 56, 56, 64)   36928       re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 56, 56, 64)   256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_16 (TensorFlo [(None, 56, 56, 64)] 0           batch_normalization_33[0][0]     \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 56, 56, 64)   0           tf_op_layer_AddV2_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 56, 56, 64)   36928       re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 56, 56, 64)   256         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                 (None, 56, 56, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 56, 56, 64)   36928       re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 56, 56, 64)   256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_17 (TensorFlo [(None, 56, 56, 64)] 0           batch_normalization_35[0][0]     \n",
      "                                                                 re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                 (None, 56, 56, 64)   0           tf_op_layer_AddV2_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 28, 28, 128)  73856       re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 28, 28, 128)  512         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_36 (ReLU)                 (None, 28, 28, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 28, 28, 128)  147584      re_lu_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 28, 28, 128)  512         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 28, 28, 128)  8320        re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_18 (TensorFlo [(None, 28, 28, 128) 0           batch_normalization_37[0][0]     \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_37 (ReLU)                 (None, 28, 28, 128)  0           tf_op_layer_AddV2_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 28, 28, 128)  147584      re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 28, 28, 128)  512         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                 (None, 28, 28, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 28, 28, 128)  147584      re_lu_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 28, 28, 128)  512         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_19 (TensorFlo [(None, 28, 28, 128) 0           batch_normalization_39[0][0]     \n",
      "                                                                 re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, 28, 28, 128)  0           tf_op_layer_AddV2_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 14, 14, 256)  295168      re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 14, 14, 256)  590080      re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 14, 14, 256)  33024       re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_20 (TensorFlo [(None, 14, 14, 256) 0           batch_normalization_41[0][0]     \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                 (None, 14, 14, 256)  0           tf_op_layer_AddV2_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 14, 14, 256)  590080      re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 256)  1024        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_42 (ReLU)                 (None, 14, 14, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 14, 14, 256)  590080      re_lu_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 14, 14, 256)  1024        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_21 (TensorFlo [(None, 14, 14, 256) 0           batch_normalization_43[0][0]     \n",
      "                                                                 re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_43 (ReLU)                 (None, 14, 14, 256)  0           tf_op_layer_AddV2_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 512)    1180160     re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_44 (ReLU)                 (None, 7, 7, 512)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 512)    2359808     re_lu_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 512)    2048        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 512)    131584      re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_22 (TensorFlo [(None, 7, 7, 512)]  0           batch_normalization_45[0][0]     \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_45 (ReLU)                 (None, 7, 7, 512)    0           tf_op_layer_AddV2_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 512)    2359808     re_lu_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 512)    2048        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_46 (ReLU)                 (None, 7, 7, 512)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 512)    2359808     re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_23 (TensorFlo [(None, 7, 7, 512)]  0           batch_normalization_47[0][0]     \n",
      "                                                                 re_lu_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_47 (ReLU)                 (None, 7, 7, 512)    0           tf_op_layer_AddV2_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 512)          0           re_lu_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            1026        global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 11,188,098\n",
      "Trainable params: 11,180,418\n",
      "Non-trainable params: 7,680\n",
      "__________________________________________________________________________________________________\n",
      "2022-07-14 11:44:36 - INFO - _train:94 - Saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "Epoch 1/50\n",
      " 2/12 [====>.........................] - ETA: 2s - loss: 6.4806 - categorical_accuracy: 0.4980 - auc: 0.66332022-07-14 11:44:42 - WARNING - callbacks:325 - Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1153s vs `on_train_batch_end` time: 0.1776s). Check your callbacks.\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9204 - categorical_accuracy: 0.7831 - auc: 0.7897\n",
      "Epoch 00001: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 318ms/step - loss: 1.9204 - categorical_accuracy: 0.7831 - auc: 0.7897\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4456 - categorical_accuracy: 0.8426 - auc: 0.8514\n",
      "Epoch 00002: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 321ms/step - loss: 0.4456 - categorical_accuracy: 0.8426 - auc: 0.8514\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4322 - categorical_accuracy: 0.8461 - auc: 0.8654\n",
      "Epoch 00003: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 314ms/step - loss: 0.4322 - categorical_accuracy: 0.8461 - auc: 0.8654\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3927 - categorical_accuracy: 0.8464 - auc: 0.9040\n",
      "Epoch 00004: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 318ms/step - loss: 0.3927 - categorical_accuracy: 0.8464 - auc: 0.9040\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3301 - categorical_accuracy: 0.8796 - auc: 0.9251\n",
      "Epoch 00005: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 317ms/step - loss: 0.3301 - categorical_accuracy: 0.8796 - auc: 0.9251\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3271 - categorical_accuracy: 0.8897 - auc: 0.9214\n",
      "Epoch 00006: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 317ms/step - loss: 0.3271 - categorical_accuracy: 0.8897 - auc: 0.9214\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3060 - categorical_accuracy: 0.9025 - auc: 0.9301\n",
      "Epoch 00007: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 319ms/step - loss: 0.3060 - categorical_accuracy: 0.9025 - auc: 0.9301\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3049 - categorical_accuracy: 0.9070 - auc: 0.9271\n",
      "Epoch 00008: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 319ms/step - loss: 0.3049 - categorical_accuracy: 0.9070 - auc: 0.9271\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2905 - categorical_accuracy: 0.9011 - auc: 0.9388\n",
      "Epoch 00009: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 320ms/step - loss: 0.2905 - categorical_accuracy: 0.9011 - auc: 0.9388\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2903 - categorical_accuracy: 0.9052 - auc: 0.9343\n",
      "Epoch 00010: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 320ms/step - loss: 0.2903 - categorical_accuracy: 0.9052 - auc: 0.9343\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2786 - categorical_accuracy: 0.9118 - auc: 0.9405\n",
      "Epoch 00011: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2786 - categorical_accuracy: 0.9118 - auc: 0.9405\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2670 - categorical_accuracy: 0.9139 - auc: 0.9440\n",
      "Epoch 00012: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2670 - categorical_accuracy: 0.9139 - auc: 0.9440\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2574 - categorical_accuracy: 0.9146 - auc: 0.9468\n",
      "Epoch 00013: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 320ms/step - loss: 0.2574 - categorical_accuracy: 0.9146 - auc: 0.9468\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2865 - categorical_accuracy: 0.9111 - auc: 0.9368\n",
      "Epoch 00014: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2865 - categorical_accuracy: 0.9111 - auc: 0.9368\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2765 - categorical_accuracy: 0.9121 - auc: 0.9429\n",
      "Epoch 00015: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 320ms/step - loss: 0.2765 - categorical_accuracy: 0.9121 - auc: 0.9429\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2760 - categorical_accuracy: 0.9111 - auc: 0.9406\n",
      "Epoch 00016: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 321ms/step - loss: 0.2760 - categorical_accuracy: 0.9111 - auc: 0.9406\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2612 - categorical_accuracy: 0.9198 - auc: 0.9450\n",
      "Epoch 00017: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 321ms/step - loss: 0.2612 - categorical_accuracy: 0.9198 - auc: 0.9450\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2580 - categorical_accuracy: 0.9201 - auc: 0.9465\n",
      "Epoch 00018: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2580 - categorical_accuracy: 0.9201 - auc: 0.9465\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2572 - categorical_accuracy: 0.9149 - auc: 0.9509\n",
      "Epoch 00019: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 325ms/step - loss: 0.2572 - categorical_accuracy: 0.9149 - auc: 0.9509\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2688 - categorical_accuracy: 0.9159 - auc: 0.9459\n",
      "Epoch 00020: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2688 - categorical_accuracy: 0.9159 - auc: 0.9459\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2670 - categorical_accuracy: 0.9132 - auc: 0.9455\n",
      "Epoch 00021: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2670 - categorical_accuracy: 0.9132 - auc: 0.9455\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2566 - categorical_accuracy: 0.9187 - auc: 0.9481\n",
      "Epoch 00022: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2566 - categorical_accuracy: 0.9187 - auc: 0.9481\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2574 - categorical_accuracy: 0.9173 - auc: 0.9486\n",
      "Epoch 00023: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 321ms/step - loss: 0.2574 - categorical_accuracy: 0.9173 - auc: 0.9486\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2570 - categorical_accuracy: 0.9166 - auc: 0.9493\n",
      "Epoch 00024: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 320ms/step - loss: 0.2570 - categorical_accuracy: 0.9166 - auc: 0.9493\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2566 - categorical_accuracy: 0.9149 - auc: 0.9539\n",
      "Epoch 00025: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2566 - categorical_accuracy: 0.9149 - auc: 0.9539\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2549 - categorical_accuracy: 0.9184 - auc: 0.9494\n",
      "Epoch 00026: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 323ms/step - loss: 0.2549 - categorical_accuracy: 0.9184 - auc: 0.9494\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2503 - categorical_accuracy: 0.9215 - auc: 0.9523\n",
      "Epoch 00027: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 326ms/step - loss: 0.2503 - categorical_accuracy: 0.9215 - auc: 0.9523\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2511 - categorical_accuracy: 0.9170 - auc: 0.9536\n",
      "Epoch 00028: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 325ms/step - loss: 0.2511 - categorical_accuracy: 0.9170 - auc: 0.9536\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2553 - categorical_accuracy: 0.9170 - auc: 0.9530\n",
      "Epoch 00029: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 321ms/step - loss: 0.2553 - categorical_accuracy: 0.9170 - auc: 0.9530\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2542 - categorical_accuracy: 0.9173 - auc: 0.9524\n",
      "Epoch 00030: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 323ms/step - loss: 0.2542 - categorical_accuracy: 0.9173 - auc: 0.9524\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2516 - categorical_accuracy: 0.9201 - auc: 0.9524\n",
      "Epoch 00031: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 323ms/step - loss: 0.2516 - categorical_accuracy: 0.9201 - auc: 0.9524\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2542 - categorical_accuracy: 0.9153 - auc: 0.9540\n",
      "Epoch 00032: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 324ms/step - loss: 0.2542 - categorical_accuracy: 0.9153 - auc: 0.9540\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2592 - categorical_accuracy: 0.9163 - auc: 0.9503\n",
      "Epoch 00033: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2592 - categorical_accuracy: 0.9163 - auc: 0.9503\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2603 - categorical_accuracy: 0.9142 - auc: 0.9502\n",
      "Epoch 00034: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 324ms/step - loss: 0.2603 - categorical_accuracy: 0.9142 - auc: 0.9502\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2387 - categorical_accuracy: 0.9232 - auc: 0.9596\n",
      "Epoch 00035: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2387 - categorical_accuracy: 0.9232 - auc: 0.9596\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2452 - categorical_accuracy: 0.9232 - auc: 0.9548\n",
      "Epoch 00036: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 327ms/step - loss: 0.2452 - categorical_accuracy: 0.9232 - auc: 0.9548\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2374 - categorical_accuracy: 0.9242 - auc: 0.9593\n",
      "Epoch 00037: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2374 - categorical_accuracy: 0.9242 - auc: 0.9593\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2509 - categorical_accuracy: 0.9201 - auc: 0.9544\n",
      "Epoch 00038: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 324ms/step - loss: 0.2509 - categorical_accuracy: 0.9201 - auc: 0.9544\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2496 - categorical_accuracy: 0.9232 - auc: 0.9549\n",
      "Epoch 00039: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 324ms/step - loss: 0.2496 - categorical_accuracy: 0.9232 - auc: 0.9549\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2560 - categorical_accuracy: 0.9187 - auc: 0.9509\n",
      "Epoch 00040: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 326ms/step - loss: 0.2560 - categorical_accuracy: 0.9187 - auc: 0.9509\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2459 - categorical_accuracy: 0.9225 - auc: 0.9546\n",
      "Epoch 00041: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2459 - categorical_accuracy: 0.9225 - auc: 0.9546\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2368 - categorical_accuracy: 0.9260 - auc: 0.9589\n",
      "Epoch 00042: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 324ms/step - loss: 0.2368 - categorical_accuracy: 0.9260 - auc: 0.9589\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2341 - categorical_accuracy: 0.9242 - auc: 0.9608\n",
      "Epoch 00043: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 326ms/step - loss: 0.2341 - categorical_accuracy: 0.9242 - auc: 0.9608\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2322 - categorical_accuracy: 0.9222 - auc: 0.9628\n",
      "Epoch 00044: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 325ms/step - loss: 0.2322 - categorical_accuracy: 0.9222 - auc: 0.9628\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2380 - categorical_accuracy: 0.9211 - auc: 0.9605\n",
      "Epoch 00045: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 325ms/step - loss: 0.2380 - categorical_accuracy: 0.9211 - auc: 0.9605\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2491 - categorical_accuracy: 0.9180 - auc: 0.9536\n",
      "Epoch 00046: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 329ms/step - loss: 0.2491 - categorical_accuracy: 0.9180 - auc: 0.9536\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2470 - categorical_accuracy: 0.9215 - auc: 0.9553\n",
      "Epoch 00047: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 324ms/step - loss: 0.2470 - categorical_accuracy: 0.9215 - auc: 0.9553\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2426 - categorical_accuracy: 0.9201 - auc: 0.9575\n",
      "Epoch 00048: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 324ms/step - loss: 0.2426 - categorical_accuracy: 0.9201 - auc: 0.9575\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2502 - categorical_accuracy: 0.9166 - auc: 0.9548\n",
      "Epoch 00049: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 321ms/step - loss: 0.2502 - categorical_accuracy: 0.9166 - auc: 0.9548\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2385 - categorical_accuracy: 0.9218 - auc: 0.9600\n",
      "Epoch 00050: saving model to /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 0.2385 - categorical_accuracy: 0.9218 - auc: 0.9600\n",
      "2022-07-14 11:48:09 - INFO - _train:113 - Trained model for 50 epochs\n",
      "2022-07-14 11:48:09 - INFO - _train:118 - Saved training history to /mnt/data5/output/train/colon-epithelium/history.csv\n",
      "2022-07-14 11:48:10 - INFO - _train:121 - Loaded best model from /mnt/data5/output/train/colon-epithelium/model.h5\n",
      "2022-07-14 11:48:13 - INFO - _train:137 - Generated train predictions to /mnt/data5/output/train/colon-epithelium/train_predictions.csv\n",
      "2022-07-14 11:48:13 - INFO - _train:155 - Generated test predictions to /mnt/data5/output/train/colon-epithelium/test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    label='epithelium',\n",
    "    num_classes=2,\n",
    "    train_csv='/mnt/data5/output/tiles/gi-infection-scaled/C.diff/C1/epithelium.csv',\n",
    "    activation='softmax',\n",
    "    batch_size=256,\n",
    "    epochs=50,\n",
    "    lr=0.01,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy', 'AUC'],\n",
    "    output_dir='/mnt/data5/output/train/colon-epithelium',\n",
    "    num_workers=4,\n",
    "    callback_monitor='loss',\n",
    "    cache=True,\n",
    "    shuffle_train=True,\n",
    "    augment_train=True,\n",
    "    balance_train=False,\n",
    "    test_csv='/mnt/data5/output/tiles/gi-infection-scaled/C.diff/B1/epithelium.csv',\n",
    "    gpu_config=(0, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ed79464-92a1-4ea4-ae6e-dbf03bd4ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9abd9d7-8da2-4556-bb58-71f194ce8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true = pd.read_csv('/mnt/data5/output/tiles/gi-infection-scaled/C.diff/C1/epithelium.csv')['epithelium']\n",
    "train_pred = pd.read_csv('/mnt/data5/output/train/colon-epithelium/train_predictions.csv')['epithelium']\n",
    "\n",
    "test_true = pd.read_csv('/mnt/data5/output/tiles/gi-infection-scaled/C.diff/B1/epithelium.csv')['epithelium']\n",
    "test_pred = pd.read_csv('/mnt/data5/output/train/colon-epithelium/test_predictions.csv')['epithelium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8565ec63-3f28-46d8-8cae-73e21143c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8271662-6262-4580-87e3-75f7e7090914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0c0c386e80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_fpr, train_tpr, _ = roc_curve(train_true, train_pred)\n",
    "test_fpr, test_tpr, _ = roc_curve(test_true, test_pred)\n",
    "plt.plot(train_fpr, train_tpr, label=f'{auc(train_fpr, train_tpr):0.3f}')\n",
    "plt.plot(test_fpr, test_tpr, label=f'{auc(test_fpr, test_tpr):0.3f}')\n",
    "plt.plot([0,1], [0,1], linestyle='--', color='grey')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0988e1-28f8-4497-9ceb-3738f816a89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
